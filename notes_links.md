



| #    | Link                                                         | Description                                                  | Article          |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------- |
| 1    | [Installing the Concorde TSP Solver on a Mac and Using it in RStudio’s TSP Package](https://nityasriram.medium.com/installing-the-concorde-tsp-solver-on-a-mac-and-using-it-in-rstudios-tsp-package-ffca9dfa9548) | Does not work for new Xcode                                  | -                |
| 2    | [TSP package: Traveling Salesperson Problem (TSP)](https://cran.r-project.org/web/packages/TSP/index.html) | Basic infrastructure and some algorithms for the traveling salesperson problem (also traveling salesman problem; TSP). | -                |
| 3    | [R algos The Traveling Salesman Problem](https://rpubs.com/mstefan-rpubs/salesman) |                                                              | Basic heuristics |
| 4    | [Concorde](https://www.math.uwaterloo.ca/tsp/index.html)     | Concorde source data                                         | Basic heuristics |
| 5    | [Traveling Santa 2018 - Prime Paths](https://www.kaggle.com/competitions/traveling-santa-2018-prime-paths/overview) | Concord solution for elk pic                                 | Basic heuristics |
| 6    | [The Chistofides Algorithm - Alon Krymgand](https://alon.kr/posts/christofides) | Cristofides description                                      | Cristofides      |
| 7    | [Christofides algorithm](https://github.com/Retsediv/ChristofidesAlgorithm) | Cristofides implementation                                   | -                |
| 8    | [Top 10 Secrets of Pascal’s Triangle](https://medium.com/i-math/top-10-secrets-of-pascals-triangle-6012ba9c5e23) | Basically about combinatorial connection between Pascal Triangle and binomial distribution | -                |
| 9    | [christofides — NetworkX 3.4.2 documentation](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.approximation.traveling_salesman.christofides.html) | Cristofides implementation in Networks                       | Cristofides      |
| 10   | [TranSPormer: A Transformer Network for the Travelling Salesman Problem](https://towardsdatascience.com/transpormer-a-transformer-network-for-the-travelling-salesman-problem-154bd33c37b0) | An original approach to tackle TSP leveraging a Transformer neural network | Cristofides      |
|      | [TranSPormer: a transformer for the Travelling Salesman Problem](https://github.com/dcaffo98/transpormer/tree/master) | This repository presents a proof-of-concept of a transformer neural network to address the Travelling Salesman Problem avoiding any auto-regressive component. |                  |
| 11   | [Modified Hopfield Network ](https://github.com/DenseLance/hopfield-networks/blob/main/Modified%20Hopfield%20Network%20(Travelling%20Salesman%20Problem).ipynb) | A Brief Walkthrough of Hopfield Networks                     | -                |
| 12   | [tsp-attention](https://github.com/CarlossShi/tsp-attention?tab=readme-ov-file) | Attention model for solving Traveling Salesman Problem (TSP), implemented by Pytorch with Policy Optimization with Multiple Optima (POMO) baseline. |                  |
| 13   | [TSP Transformer](https://github.com/xbresson/TSP_Transformer/blob/main/test_tsp_transformer_beamsearch_TSP100.ipynb) | PyTorch implementation of "The Transformer Network for the Traveling Salesman Problem"<br/>Xavier Bresson and Thomas Laurent |                  |
| 14   | [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/) | In this tutorial I’ll show you how to use BERT with the huggingface PyTorch library to quickly and efficiently fine-tune a model to get near state of the art performance in sentence classification. |                  |
| 15   | [Понимание Q-learning, проблема «Прогулка по скале»](https://habr.com/ru/articles/443240/) |                                                              |                  |
| 16   | [Всё, что вам нужно — это внимание (часть 1)](https://habr.com/ru/companies/ruvds/articles/723538/) |                                                              |                  |
| 17   | [Transformer в картинках](https://habr.com/ru/articles/486358/) |                                                              |                  |
| 18   | [Pointer Networks](https://arxiv.org/abs/1506.03134)         | We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. |                  |
| 19   | [Neural Combinatorial Optimization with Reinforcement Learning](https://arxiv.org/abs/1611.09940) | This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. |                  |
| 20   | [Attention Is All You Need](https://arxiv.org/abs/1706.03762) | The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. | Pointer Network  |
| 21   | [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) | Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. | Pointer Network  |
| 22   | [Torch](https://torch.mlverse.org/)                          | R implementation of Torch aka PyTorch package                | Pointer Network  |
| 23   | [Pointer Network in R](https://www.kaggle.com/code/dmitrykibalnikov/pointer-network-in-r?scriptVersionId=213658878) | R implementation of Pointer Network hosted on Kaggle to test GPU acceleration | Pointer Network  |
| 24   | [The Bahdanau Attention Mechanism](https://d2l.ai/chapter_attention-mechanisms-and-transformers/bahdanau-attention.html) | Dive into Deep Learning                                      | Pointer Network  |
| 25   |                                                              |                                                              |                  |
| 26   |                                                              |                                                              |                  |
| 27   |                                                              |                                                              |                  |
| 28   |                                                              |                                                              |                  |
| 29   |                                                              |                                                              |                  |
| 30   |                                                              |                                                              |                  |
| 31   |                                                              |                                                              |                  |
| 32   |                                                              |                                                              |                  |
| 33   |                                                              |                                                              |                  |
| 34   |                                                              |                                                              |                  |
|      |                                                              |                                                              |                  |
|      |                                                              |                                                              |                  |
|      |                                                              |                                                              |                  |
|      |                                                              |                                                              |                  |

